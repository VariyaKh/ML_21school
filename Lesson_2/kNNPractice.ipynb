{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуем метод predict_proba для kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание взято с курсов [DMIA](https://vk.com/data_mining_in_action)   \n",
    "Репозиторий DMIA https://github.com/utd-ai/DMIA2018_Fall_public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже реализован класс KNeighborsClassifier, который для поиска ближайших соседей использует sklearn.neighbors.NearestNeighbors\n",
    "\n",
    "Требуется реализовать метод predict_proba для вычисления ответа классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "class KNeighborsClassifier(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Класс, который позволит нам изучить KNN\n",
    "    '''\n",
    "    def __init__(self, n_neighbors=5, weights='uniform', \n",
    "                 metric='minkowski', p=2):\n",
    "        '''\n",
    "        Инициализируем KNN с несколькими стандартными параметрами\n",
    "        '''\n",
    "        assert weights in ('uniform', 'distance')\n",
    "        \n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.NearestNeighbors = NearestNeighbors(\n",
    "            n_neighbors = n_neighbors,\n",
    "            metric = self.metric)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Используем sklearn.neighbors.NearestNeighbors \n",
    "        для запоминания обучающей выборки\n",
    "        и последующего поиска соседей\n",
    "        '''\n",
    "        self.NearestNeighbors.fit(X)\n",
    "        self.labels = np.unique(y)\n",
    "        self.n_classes = len(self.labels)\n",
    "        self.y = y\n",
    "        \n",
    "    def predict_proba(self, X, use_first_zero_distant_sample=True):\n",
    "        '''\n",
    "        Чтобы реализовать этот метод, \n",
    "        изучите работу sklearn.neighbors.NearestNeighbors'''\n",
    "        \n",
    "        # получим здесь расстояния до соседей distances и их метки\n",
    "        # воспользуйтесь методом NearestNeighbors\n",
    "        distances, indices = # TODO\n",
    "        \n",
    "        if self.weights == 'uniform':\n",
    "            w = np.ones(distances.shape)\n",
    "        else:\n",
    "            # чтобы не делить на 0, \n",
    "            # добавим небольшую константу, например 1e-3\n",
    "            w = 1/(distances + 1e-3)\n",
    "            \n",
    "        nearest_label = self.y[[indices]]\n",
    "        \n",
    "        # TODO\n",
    "        \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные и обучим классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance')\n",
    "knn.fit(X, y)\n",
    "prediction = knn.predict_proba(X, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы используем одну и ту же выборку для обучения и предсказания, ближайшим соседом любого объекта будет он же сам. В качестве упражнения предлагаю реализовать метод transform, который реализует получение предсказаний для обучающей выборки, но для каждого объекта не будет учитывать его самого.\n",
    "\n",
    "Посмотрим, в каких объектах max(prediction) != 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 56  68  70  72  77  83 106 110 119 123 127 133 134 138 146]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = np.arange(len(prediction))[prediction.max(1) != 1]\n",
    "print(inds)\n",
    "(inds == [ 56,  68,  70,72,  77,  83, 106, 110, 119, 123, 127, 133, 134, 138, 146]).all()\n",
    "# [ 56  68  70  72  77  83 106 110 119 123 127 133 134 138 146]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько примеров, на которых можно проверить правильность реализованного метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 [0.         0.99816311 0.00183689]\n",
      "77 [0.         0.99527902 0.00472098]\n",
      "146 [0.         0.00239145 0.99760855]\n"
     ]
    }
   ],
   "source": [
    "for i in 1, 4, -1:\n",
    "    print(inds[i], prediction[inds[i]])\n",
    "\n",
    "# 68 [0.         0.99816311 0.00183689]\n",
    "# 77 [0.         0.99527902 0.00472098]\n",
    "# 146 [0.         0.00239145 0.99760855]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
